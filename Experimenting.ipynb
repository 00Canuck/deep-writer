{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_18:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.constant(5)\n",
    "x2 = tf.constant(6)\n",
    "result = x1*x2  #inefficient way\n",
    "result = tf.multiply(x1,x2)\n",
    "'''x1_mat = tf.constant([56,6])\n",
    "x2_mat = tf.constant([6,6;6,6])\n",
    "result = tf.matmul(x1_mat,x2_mat)'''\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session() #creates session\n",
    "print(sess.run(result))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ No process actually ran the computation until we ran the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-48dc472c7189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# so you can print the output but can't print sess.run(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# Actual, efficient way:\n",
    "# will automatically close the session, so don't have to remember to close the session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(result) # can save that as python variables to reference them\n",
    "    print(output)\n",
    "\n",
    "# so you can print the output but can't print sess.run(result)\n",
    "print(output)\n",
    "print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using feed-forward Neural Network\n",
    "\n",
    "(Basic MLP)\n",
    "input > weights > hidden layer 1 (activation function) > weights > hidden layer 2 (activation function) > weights > output layer\n",
    "\n",
    "compare output with intended output > assign a cost function or loss function\n",
    "\n",
    "optimization function (optimizer) > minimize cost (e.g. AdamOptimizer, Stochastic Gradient Descent, AdaGrad)\n",
    "\"Goes backwards and manipulates the weights accordingly\" - backpropagation\n",
    "\n",
    "FFN + backprop = epoch\n",
    "lowering the cost function with each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<< 1 hidden layer = regular neural net.\n",
    "2 or more hidden layers = deep neural net >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-090fb67c9be4>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 done. Epoch loss =  1744421.0326385498\n",
      "Epoch  1 done. Epoch loss =  399354.0344619751\n",
      "Epoch  2 done. Epoch loss =  224111.1451063156\n",
      "Epoch  3 done. Epoch loss =  133647.82119944692\n",
      "Epoch  4 done. Epoch loss =  83260.95193886757\n",
      "Epoch  5 done. Epoch loss =  51629.15432609675\n",
      "Epoch  6 done. Epoch loss =  37299.55490410328\n",
      "Epoch  7 done. Epoch loss =  27306.909869850148\n",
      "Epoch  8 done. Epoch loss =  20420.21962215049\n",
      "Epoch  9 done. Epoch loss =  16788.007174332888\n",
      "Accuracy:  0.9501\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "10 classes, 0-9\n",
    "\n",
    "0 = [1,0,0,0,0,0,0,0,0,0]\n",
    "1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "2 = [0,0,1,0,0,0,0,0,0,0]\n",
    "etc\n",
    "\n",
    "ONE element is 'hot' or 'on'\n",
    "and the rest are 'cold' or 'off'\n",
    "\"\"\"\n",
    "\n",
    "# defining our model\n",
    "# we will have 3 hidden layers\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500 # donot have to be equal in number. It can be 500,1500,15\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100 \n",
    "# ^ gonna go through batches of 100 features & feed them through our network at a time \n",
    "# and manipulate the weights and then do another batch - by batches of a 100 images. We can do 1000 images too etc\n",
    "\n",
    "# defining placeholder variables\n",
    "x = tf.placeholder('float',[None,784]) # 784 because the images in the dataset are 28x28 = 784 values/pixels\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def neural_network_model(data):\n",
    "    \n",
    "    # (input_data * weights) + biases <- model for each layer\n",
    "    # biases because if the inputs are something like 0, then we need something to equal it out\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784,n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1,n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1) # relu = rectified linear, which is the activation function that we are using. Like a threshold fn\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "    \n",
    "    return output\n",
    "    # We have finished coding the model.\n",
    "    # Now we have to tell tensorflow what to do in this model and what to do in the session\n",
    "\n",
    "def train_neural_network(x): # x is just the input data\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    # ^ using cross entropy with logits as our cost function here\n",
    "    \n",
    "    # now to minimize this cost function\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    # an epoch = ffn + backprop\n",
    "    epochs = 10\n",
    "    \n",
    "    with tf.Session() as ses:\n",
    "        ses.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "                epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = ses.run([optimizer, cost], feed_dict = {x:epoch_x, y:epoch_y}) # c is cost\n",
    "                # somehow, tensorflow knows it has to modify the weights so it does without us having to explicitly code it\n",
    "                \n",
    "                epoch_loss += c\n",
    "            print('Epoch ',e,'done. Epoch loss = ',epoch_loss)\n",
    "            \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('Accuracy: ',accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% on the mnist dataset is considered laughable. Because this is not quite the best model.\n",
    "But all we did was feed through raw pixel values. We didn't help it generalize, we didn't help it have a different perspective or anything. \n",
    "\n",
    "Like CNN will be taking chunks of the pixels and those are the layers or whatever.\n",
    "It has a little bit more of a logical approach.\n",
    "Whereas, here, we're just throwing data at the neural net and telling it to figure it out.\n",
    "Which it did, considering everything. Even though it isn't the industry standard for this task, it did pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MLP etc there is no sense of time or order of events.\n",
    "E.g. Harry killed Bill.\n",
    "Traditional Deep Neurals Nets will not know the difference between Harry killed Bill and Bill killed Harry\n",
    "\n",
    "RNN, CNN have a sense of order.\n",
    "\n",
    "RNN used more with language data\n",
    "CNN used more with image data - for single frames\n",
    "For successions of frames etc, combo of CNN-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input > activation fn > output \n",
    "then the output serves as input again to the activation function\n",
    "so\n",
    "\n",
    "\n",
    "x1 > A() > o1\n",
    "\n",
    "      v\n",
    "x2 > A() > o2\n",
    "\n",
    "      v\n",
    "x3 > A() > o3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function has a forget gate which decides what to keep from the previoud output\n",
    "It also decides what to add from the input and then finally what to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.]]],\n",
       "\n",
       "\n",
       "       [[[1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.]]],\n",
       "\n",
       "\n",
       "       [[[1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.ones((3,2,2,1)) # total 3, each has 2, then those 2 each have 2, those each have 1\n",
    "np.transpose(x,(1,0,2,3)) # transpose the axes\n",
    "# so now each 2 has 3 and those 3 have 2 and those 2 have 1 (cuz axes 0 and 1 got exchanged)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "mnist = input_data.read_data_sets('data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-a33652150fee>:23: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-a33652150fee>:24: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-4-a33652150fee>:32: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch  0 done. Epoch loss =  188.49540507793427\n",
      "Epoch  1 done. Epoch loss =  55.29036856070161\n",
      "Epoch  2 done. Epoch loss =  37.6534407697618\n",
      "Accuracy:  0.9731\n"
     ]
    }
   ],
   "source": [
    "hm_epochs = 3\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "chunk_size = 28\n",
    "n_chunks = 28 # 28 chunks of 28 pixels cuz the image is 28x28\n",
    "rnn_size = 128 # rather than having all those layers, we just have a single size of the rnn which is 128\n",
    "\n",
    "x = tf.placeholder('float',[None,n_chunks,chunk_size])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "def recurrent_neural_network(data):\n",
    "    \n",
    "    layer = {'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),\n",
    "             'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    global x\n",
    "    # formatting the data cuz rnn wants it in a certain format\n",
    "    # just like we need to reshape the data for sklearn\n",
    "    x = tf.transpose(x,[1,0,2])\n",
    "    x = tf.reshape(x,[-1,chunk_size])\n",
    "    x = tf.split(x,n_chunks,0)\n",
    "    \n",
    "    lstm_cell = rnn.BasicLSTMCell(rnn_size) # a basic lstm cell that with recur, that is of rnn size\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    \n",
    "    output = tf.matmul(outputs[-1],layer['weights']) + layer['biases'] # final output * weights + biases\n",
    "    \n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as ses:\n",
    "        ses.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples / batch_size)):\n",
    "                epoch_x,epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = epoch_x.reshape((batch_size,n_chunks,chunk_size))\n",
    "                \n",
    "                _, c = ses.run([optimizer, cost], feed_dict = {x:epoch_x, y:epoch_y})\n",
    "                # reshape images by -1 because each individual image and not the batch size\n",
    "                \n",
    "                epoch_loss += c\n",
    "            print('Epoch ',epoch,'done. Epoch loss = ',epoch_loss)\n",
    "            \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        print('Accuracy: ',accuracy.eval({x:mnist.test.images.reshape((-1,n_chunks,chunk_size)),y:mnist.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
